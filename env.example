# ==============================================================================
# LanguageAIApp Deployment Configuration
# ==============================================================================
# Copy this file to .env and update the values for your deployment
# cp env.example .env

# ==============================================================================
# DEPLOYMENT CONFIGURATION
# ==============================================================================

# Remote server details
REMOTE_HOST=192.168.50.25
REMOTE_USER=bence
DEPLOY_PATH=/home/bence/language-ai-app

# Port configuration
DEPLOY_PORT=3499
CACHE_HOST_DIR=/var/lib/language-ai-app

# ==============================================================================
# DOCKER CONFIGURATION
# ==============================================================================

# Docker image details
IMAGE_NAME=language-ai-app
IMAGE_TAG=latest

# Docker registry configuration
# Use the same host as your deployment server if running registry locally
REGISTRY_HOST=192.168.50.25
REGISTRY_PORT=5010

# ==============================================================================
# APPLICATION CONFIGURATION
# ==============================================================================

# LLM Provider Configuration
PROVIDER=anthropic

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-5-sonnet-20240620

# OpenRouter Configuration
OPENROUTER_API_KEY=your-openrouter-api-key
OPENROUTER_MODEL=anthropic/claude-3-5-sonnet

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4o-mini

# Ollama Configuration
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_MODEL=qwen2.5:14b

# Image Generation Configuration
IMAGE_PROVIDER=runware

# Runware Configuration
RUNWARE_API_KEY=your-runware-api-key
RUNWARE_MODEL=runware:100@1
RUNWARE_ENABLED=false
RUNWARE_WIDTH=512
RUNWARE_HEIGHT=512
RUNWARE_STEPS=20
RUNWARE_CFG_SCALE=7

# fal.ai Configuration
FALAI_API_KEY=your-falai-api-key
FALAI_MODEL=fal-ai/fast-sdxl
FALAI_ENABLED=false
FALAI_WIDTH=512
FALAI_HEIGHT=512
FALAI_STEPS=20
FALAI_CFG_SCALE=7

# Application URL
APP_URL=http://localhost:3000

# Max tokens cap for generations (server-enforced)
MAX_TOKENS=15000

# Persistent cache limits
CACHE_DIR=/data
CACHE_EXPLANATIONS_MAX=1000
CACHE_EXERCISES_PER_TYPE_MAX=100
COOKIE_MAX_SEEN_PER_TYPE=50

# ==============================================================================
# NOTES
# ==============================================================================
# 1. Update REMOTE_HOST with your actual server IP address
# 2. Update REMOTE_USER with your server username
# 3. Update DEPLOY_PORT if you want to use a different port
# 4. Set your actual API keys for the LLM providers you want to use
# 5. REGISTRY_HOST should point to your Docker registry server
# 6. REGISTRY_PORT defaults to 5010 (common for local registries)
# 7. Make sure your Docker daemon is configured with insecure-registries if using HTTP
